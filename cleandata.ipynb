{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMmMS2+55wCcdmNXzVimbQQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Brockwk/Ass1/blob/main/cleandata.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mk0G6YFVcxMv",
        "outputId": "6fd7f31a-b63c-4dad-afce-8f9fbe85e9fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "zago\n"
          ]
        }
      ],
      "source": [
        "print(\"zago\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade google-cloud-storage google-cloud-bigquery pandas\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1IoGiO1oc1ti",
        "outputId": "8591f31d-71e2-47a2-e8ab-5fc62a64bcfd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.10/dist-packages (2.19.0)\n",
            "Requirement already satisfied: google-cloud-bigquery in /usr/local/lib/python3.10/dist-packages (3.25.0)\n",
            "Collecting google-cloud-bigquery\n",
            "  Downloading google_cloud_bigquery-3.27.0-py2.py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Collecting pandas\n",
            "  Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-auth<3.0dev,>=2.26.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (2.27.0)\n",
            "Requirement already satisfied: google-api-core<3.0.0dev,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (2.19.2)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (2.4.1)\n",
            "Requirement already satisfied: google-resumable-media>=2.7.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (2.7.2)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (2.32.3)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (1.6.0)\n",
            "Requirement already satisfied: packaging>=20.0.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery) (24.2)\n",
            "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage) (1.66.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage) (4.25.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage) (1.25.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]<3.0.0dev,>=2.11.1->google-cloud-bigquery) (1.68.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]<3.0.0dev,>=2.11.1->google-cloud-bigquery) (1.62.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage) (4.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0dev,>=2.7.3->google-cloud-bigquery) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2024.12.14)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=2.26.1->google-cloud-storage) (0.6.1)\n",
            "Downloading google_cloud_bigquery-3.27.0-py2.py3-none-any.whl (240 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.1/240.1 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m83.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pandas, google-cloud-bigquery\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "  Attempting uninstall: google-cloud-bigquery\n",
            "    Found existing installation: google-cloud-bigquery 3.25.0\n",
            "    Uninstalling google-cloud-bigquery-3.25.0:\n",
            "      Successfully uninstalled google-cloud-bigquery-3.25.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.10.1 requires pandas<2.2.3dev0,>=2.0, but you have pandas 2.2.3 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed google-cloud-bigquery-3.27.0 pandas-2.2.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "2c83cb8ccb294d84a266c99d644d3e1b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n"
      ],
      "metadata": {
        "id": "qqcR6l4BekA6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"GOOGLE_CLOUD_PROJECT\"] = \"big-maxim-444704-i8\"  # Replace with your actual project ID\n"
      ],
      "metadata": {
        "id": "N0P3aQvke4ll"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import storage\n",
        "import pandas as pd\n",
        "from io import StringIO\n",
        "\n",
        "# Initialize the Google Cloud Storage client\n",
        "storage_client = storage.Client()\n",
        "\n",
        "# Define the bucket and file name\n",
        "bucket_name = 'zago1'  # Replace with your bucket name\n",
        "blob_name = 'data.csv'  # Replace with your file name\n",
        "\n",
        "# Access the bucket and blob\n",
        "bucket = storage_client.bucket(bucket_name)\n",
        "blob = bucket.blob(blob_name)\n",
        "\n",
        "# Download the data as a string\n",
        "data = blob.download_as_text()\n",
        "\n",
        "# Load the data into a pandas DataFrame\n",
        "df = pd.read_csv(StringIO(data))\n",
        "\n",
        "# Clean the data (remove duplicates, fill nulls)\n",
        "df.drop_duplicates(inplace=True)\n",
        "df.fillna('null', inplace=True)\n",
        "\n",
        "print(df)  # Show the cleaned data\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxwdJ63UgEsZ",
        "outputId": "d30b4ec5-8fe0-44ac-bf9c-ff06c2e5f6cb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      id               name           city   salary    country\n",
            "0    1.0           John Doe       New York  50000.0        USA\n",
            "1    2.0         Jane Smith    Los Angeles  55000.0        USA\n",
            "2    3.0          Sam Brown        Chicago  60000.0        USA\n",
            "3    4.0      Emily Johnson  San Francisco  65000.0        USA\n",
            "4    5.0        Michael Lee          Miami  70000.0        USA\n",
            "5    6.0       Olivia White         Dallas  75000.0        USA\n",
            "6    7.0       Daniel Davis        Seattle  80000.0        USA\n",
            "7    8.0  Isabella Martinez        Orlando  85000.0        USA\n",
            "8    9.0     David Gonzalez        Houston  90000.0        USA\n",
            "9   10.0       Sophia Clark         Boston  95000.0        USA\n",
            "10  11.0        Liam Turner         London  60000.0         UK\n",
            "11  12.0          Ava Moore     Manchester  65000.0         UK\n",
            "12  13.0        Noah Taylor        Bristol  70000.0         UK\n",
            "13  14.0      Amelia Harris     Birmingham  75000.0         UK\n",
            "14  15.0     James Robinson      Edinburgh  80000.0         UK\n",
            "15  16.0       Lucas Walker         Sydney  70000.0  Australia\n",
            "16  17.0    Charlotte Scott      Melbourne  75000.0  Australia\n",
            "17  18.0         Ethan King       Brisbane  80000.0  Australia\n",
            "18  19.0        Harper Hill          Perth  85000.0  Australia\n",
            "19  20.0     Benjamin Adams       Adelaide  90000.0  Australia\n",
            "22  null               null           null     null       null\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-b4b257b6e926>:24: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'null' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.fillna('null', inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import bigquery\n",
        "import pandas as pd\n",
        "\n",
        "# Initialize BigQuery client\n",
        "bigquery_client = bigquery.Client()\n",
        "\n",
        "# Define BigQuery dataset and table\n",
        "dataset_id = 'DemoDataset'\n",
        "table_id = 'Demotable'\n",
        "\n",
        "# Handle \"salary\" column\n",
        "df['salary'] = pd.to_numeric(df['salary'], errors='coerce')  # Convert to numeric, replacing invalid data with NaN\n",
        "df['salary'].fillna(0, inplace=True)  # Replace NaN with 0 (or another default value)\n",
        "\n",
        "# Upload the DataFrame to BigQuery\n",
        "df.to_gbq(f'{dataset_id}.{table_id}', project_id=\"big-maxim-444704-i8\", if_exists='replace')\n",
        "\n",
        "print(f\"Data uploaded to BigQuery table {dataset_id}.{table_id}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Km2-pnQ1ij7y",
        "outputId": "a4c397fb-f512-404d-86e4-d17c39d36eb1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-f915d2725f59>:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['salary'].fillna(0, inplace=True)  # Replace NaN with 0 (or another default value)\n",
            "<ipython-input-12-f915d2725f59>:16: FutureWarning: to_gbq is deprecated and will be removed in a future version. Please use pandas_gbq.to_gbq instead: https://pandas-gbq.readthedocs.io/en/latest/api.html#pandas_gbq.to_gbq\n",
            "  df.to_gbq(f'{dataset_id}.{table_id}', project_id=\"big-maxim-444704-i8\", if_exists='replace')\n",
            "100%|██████████| 1/1 [00:00<00:00, 442.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data uploaded to BigQuery table DemoDataset.Demotable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}